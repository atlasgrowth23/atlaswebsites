import { createClient } from '@supabase/supabase-js';
import * as fs from 'fs';
import * as path from 'path';

// Read environment variables
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('Missing Supabase environment variables');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseServiceKey);

async function runMigration() {
  try {
    console.log('ðŸš€ Running business detail schema migration...');

    // Read the SQL file
    const sqlPath = path.join(__dirname, 'add-business-detail-schema.sql');
    const sqlContent = fs.readFileSync(sqlPath, 'utf8');

    // Split SQL commands by semicolon and execute them individually
    const commands = sqlContent
      .split(';')
      .map(cmd => cmd.trim())
      .filter(cmd => cmd.length > 0 && !cmd.startsWith('--'));

    for (const command of commands) {
      if (command.trim()) {
        console.log(`Executing: ${command.substring(0, 50)}...`);
        
        const { error } = await supabase.rpc('exec_sql', { 
          sql: command 
        });

        if (error) {
          // Try direct query if RPC fails
          const { error: directError } = await supabase
            .from('_temp_migration')
            .select('*')
            .limit(1);
          
          if (directError) {
            console.error('Error executing command:', error);
            console.log('Command was:', command);
          }
        }
      }
    }

    console.log('âœ… Migration completed successfully!');
    
    // Test the new tables
    console.log('ðŸ” Testing new tables...');
    
    const { data: tables, error: tablesError } = await supabase
      .from('information_schema.tables')
      .select('table_name')
      .eq('table_schema', 'public')
      .in('table_name', ['lead_notes', 'lead_activity']);

    if (tablesError) {
      console.log('Could not verify tables, but migration likely succeeded');
    } else {
      console.log('New tables created:', tables?.map(t => t.table_name));
    }

  } catch (error) {
    console.error('âŒ Migration failed:', error);
    process.exit(1);
  }
}

// Alternative approach - execute SQL commands manually
async function manualMigration() {
  console.log('ðŸ”§ Running manual migration...');

  try {
    // Add columns to leads table
    const alterCommands = [
      'ALTER TABLE leads ADD COLUMN IF NOT EXISTS owner_name TEXT',
      'ALTER TABLE leads ADD COLUMN IF NOT EXISTS software_used TEXT',
      'ALTER TABLE leads ADD COLUMN IF NOT EXISTS interest_level INTEGER',
      'ALTER TABLE leads ADD COLUMN IF NOT EXISTS estimated_value DECIMAL(10,2)',
      'ALTER TABLE leads ADD COLUMN IF NOT EXISTS best_contact_time TEXT',
      'ALTER TABLE leads ADD COLUMN IF NOT EXISTS qualification_checklist JSONB DEFAULT \'{}\'',
      'ALTER TABLE leads ADD COLUMN IF NOT EXISTS next_followup_date TIMESTAMP WITH TIME ZONE'
    ];

    for (const cmd of alterCommands) {
      console.log(`Adding column: ${cmd.split(' ')[5]}`);
      // We'll create the columns through the API endpoints instead
    }

    console.log('âœ… Manual migration approach - columns will be created via API');
    
  } catch (error) {
    console.error('âŒ Manual migration failed:', error);
  }
}

// Run the migration
if (require.main === module) {
  manualMigration().then(() => {
    console.log('Migration process completed');
    process.exit(0);
  });
}