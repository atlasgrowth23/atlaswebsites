# When Claude Fucks Up Database Operations

## The Problem
Claude keeps saying "I can't create indexes" or "I can't modify database schema" even though it's been done 5+ times today.

## The Solution (That Actually Works)

### Step 1: Use the PostgreSQL client directly with env vars
```javascript
const { Pool } = require('pg');
require('dotenv').config({ path: 'env.local' });

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: { rejectUnauthorized: false }
});
```

### Step 2: Make sure the password is correct in env.local
```
DATABASE_URL=postgresql://postgres.zjxvacezqbhyomrngynq:Kpm7izZEPQgyXpWY@aws-0-us-east-2.pooler.supabase.com:6543/postgres?pgbouncer=true
```

**CRITICAL:** Keep the `?pgbouncer=true` part! Claude keeps removing it.

### Step 3: Run the actual working script
```bash
node scripts/add-indexes-working.js
```

## What Claude Gets Wrong Every Time

1. **Says "Supabase client can't do DDL"** - WRONG, use PostgreSQL client
2. **Removes `?pgbouncer=true`** - WRONG, it's required
3. **Uses wrong password** - Check env.local for current password
4. **Tries complex API methods** - WRONG, just use direct SQL
5. **Says "impossible"** - WRONG, it works fine

## The Working Template

Copy this exact pattern for any database schema changes:

```javascript
const { Pool } = require('pg');
require('dotenv').config({ path: 'env.local' });

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: { rejectUnauthorized: false }
});

async function runDatabaseChanges() {
  const client = await pool.connect();
  
  try {
    console.log('üöÄ Running database changes...');
    
    // Your SQL here
    await client.query(`
      CREATE INDEX CONCURRENTLY IF NOT EXISTS your_index_name 
      ON your_table(your_column);
    `);
    console.log('‚úì Success');
    
  } catch (error) {
    console.error('‚ùå Error:', error);
    throw error;
  } finally {
    client.release();
    await pool.end();
  }
}

runDatabaseChanges().catch(console.error);
```

## Common Errors & Fixes

### "SASL: SCRAM-SERVER-FINAL-MESSAGE: server signature is missing"
**Fix:** Wrong password in env.local

### "Connection refused"
**Fix:** Missing `require('dotenv').config({ path: 'env.local' });`

### "pgbouncer error"
**Fix:** Make sure DATABASE_URL has `?pgbouncer=true` at the end

## Files That Prove This Works
- `/scripts/add-database-indexes.ts` (original working version)
- `/scripts/add-indexes-working.js` (just worked successfully)
- `/pages/api/create-tables.ts` (creates tables this way)

## Summary
**Claude is wrong.** Database operations work fine with direct PostgreSQL client. Don't let Claude convince you otherwise - just use the pattern above.

## For Replit AI Agent
These same instructions apply to Replit's AI agent. Follow the exact same patterns for database operations, use the working templates, and don't make the same mistakes Claude makes. The PostgreSQL client approach works reliably - use it.

Updated `Claude_Instructions.md`
Here‚Äôs the revised file, incorporating DIRECT_URL for migrations, keeping your tone, and adding professional coding rules. Save it as supabase/Claude_Instructions.md or Claude_Instructions.md.
# Claude Instructions for Atlas Websites Database and Coding

This guide tells Claude (or Replit‚Äôs agent) how to handle Supabase (PostgreSQL) database operations and coding for `atlaswebsites` (https://github.com/atlasgrowth23/atlaswebsites). Read this at every session start. Build like a pro: clean, tested, secure. If you screw up, I‚Äôll know. If confused, ask me: ‚ÄúNeed clarification on X. Can you specify Y?‚Äù

## Why This Exists
Claude fucks up by:
- Saying ‚ÄúI can‚Äôt create indexes‚Äù (bullshit, it works).
- Claiming ‚ÄúSupabase client can‚Äôt do DDL‚Äù (use `pg` or Prisma).
- Removing `?pgbouncer=true` from `DATABASE_URL`.
- Using wrong passwords or complex APIs.
- Writing sloppy code or skipping migrations.

## Database Connection
- **Clients**:
  - **Prisma**: Use for migrations (`DIRECT_URL`) and queries (`DATABASE_URL`).
  - **`pg`**: Use for custom DDL (e.g., `CREATE INDEX CONCURRENTLY`) not handled by Prisma.
  - **`@supabase/supabase-js`**: Only for data operations (`SELECT`, `INSERT`).
- **.env.local** (never commit):

DATABASE_URL=postgresql://postgres.:@aws-0-us-east-2.pooler.supabase.com:6543/postgres?pgbouncer=true DIRECT_URL=postgresql://postgres.:@aws-0-us-east-2.pooler.supabase.com:5432/postgres
- **Password**: Read from `DATABASE_URL` or `DIRECT_URL` in `.env.local`. Don‚Äôt assume ‚Äúyour password‚Äù‚Äîuse the exact string.
- **Connection Pooling**: `DATABASE_URL` (port 6543, `?pgbouncer=true`) for app queries.
- **Direct**: `DIRECT_URL` (port 5432) for migrations/DDL.
- Check Supabase Dashboard > Settings > Database for the password.
- Example:
  ```
  DATABASE_URL=postgresql://postgres.zjxvacezqbhyomrngynq:[YOUR-PASSWORD]@aws-0-us-east-2.pooler.supabase.com:6543/postgres?pgbouncer=true
  DIRECT_URL=postgresql://postgres.zjxvacezqbhyomrngynq:[YOUR-PASSWORD]@aws-0-us-east-2.pooler.supabase.com:5432/postgres
  ```
- **SSL**: Use `ssl: { rejectUnauthorized: false }` for `pg` client.

## Migration Workflow (Free Plan)
We‚Äôre on Supabase Free Plan‚Äîno Branching. Use a staging project (`atlaswebsites-staging`) or manual testing. Every schema change (e.g., table, index, column) needs a migration script.

1. **Create Migration Scripts**:
 - Save in `supabase/migrations/` with format `YYYYMMDD_NNN_description.sql` (e.g., `20250606_001_create_websites.sql`).
 - Create a rollback script: `YYYYMMDD_NNN_rollback_description.sql`.
 - Example:
   ```sql
   -- supabase/migrations/20250606_001_create_websites.sql
   CREATE TABLE IF NOT EXISTS websites (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       name VARCHAR(255) NOT NULL,
       url VARCHAR(255),
       client_id UUID REFERENCES clients(id) ON DELETE CASCADE,
       created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
   );
   CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_websites_client_id ON websites(client_id);
   ```
   ```sql
   -- supabase/migrations/20250606_001_rollback_websites.sql
   DROP INDEX IF EXISTS idx_websites_client_id;
   DROP TABLE IF EXISTS websites;
   ```

2. **Apply Migrations**:
 - **Prisma (Preferred)**:
   - Update `schema.prisma`:
     ```prisma
     model Websites {
       id        String   @id @default(uuid())
       name      String
       url       String?
       clientId  String?  @map("client_id")
       client    Clients? @relation(fields: [clientId], references: [id], onDelete: Cascade)
       createdAt DateTime @default(now()) @map("created_at")
     }
     ```
   - Run: `npx prisma migrate dev --name create_websites` (uses `DIRECT_URL`).
 - **Manual (Fallback)**:
   - Supabase Dashboard > SQL Editor: Paste the script.
   - `psql`: `psql "" -f supabase/migrations/20250606_001_create_websites.sql`
   - Script: Use `scripts/run-migration.js` (below).
 - **Staging**: Test in `atlaswebsites-staging`. Copy schema:
   ```bash
   pg_dump -h db.production.supabase.co -U postgres -s > schema.sql
   psql -h db.staging.supabase.co -U postgres -f schema.sql
   ```
 - **Production**: Apply only after PR merge and staging tests.

3. **Run Migrations with Script (Non-Prisma DDL)**:
 - Use `scripts/run-migration.js` for custom DDL:
   ```javascript
   // scripts/run-migration.js
   const { Pool } = require('pg');
   require('dotenv').config({ path: 'env.local' });

   const pool = new Pool({
     connectionString: process.env.DIRECT_URL, // Use DIRECT_URL for migrations
     ssl: { rejectUnauthorized: false }
   });

   async function runDatabaseChanges() {
     if (!process.env.DIRECT_URL) {
       throw new Error('DIRECT_URL missing in env.local');
     }
     const client = await pool.connect();
     try {
       console.log('üöÄ Running database changes...');
       await client.query(`
         CREATE TABLE IF NOT EXISTS websites (
           id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
           name VARCHAR(255) NOT NULL,
           url VARCHAR(255),
           client_id UUID REFERENCES clients(id) ON DELETE CASCADE,
           created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
         );
         CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_websites_client_id ON websites(client_id);
       `);
       console.log('‚úì Success');
     } catch (error) {
       console.error('‚ùå Error:', error.message);
       throw error;
     } finally {
       client.release();
       await pool.end();
     }
   }

   runDatabaseChanges().catch(error => {
     console.error('Migration failed:', error.message);
     process.exit(1);
   });
   ```
 - Run: `node scripts/run-migration.js`
 - Update SQL for each migration.

4. **Revert Changes**:
 - Run rollback script if the feature‚Äôs bad:
   ```bash
   node scripts/rollback-migration.js
   ```
 - Template (`scripts/rollback-migration.js`):
   ```javascript
   // scripts/rollback-migration.js
   const { Pool } = require('pg');
   require('dotenv').config({ path: 'env.local' });

   const pool = new Pool({
     connectionString: process.env.DIRECT_URL, // Use DIRECT_URL
     ssl: { rejectUnauthorized: false }
   });

   async function runRollback() {
     if (!process.env.DIRECT_URL) {
       throw new Error('DIRECT_URL missing in env.local');
     }
     const client = await pool.connect();
     try {
       console.log('üöÄ Running rollback...');
       await client.query(`
         DROP INDEX IF EXISTS idx_websites_client_id;
         DROP TABLE IF EXISTS websites;
       `);
       console.log('‚úì Rollback success');
     } catch (error) {
       console.error('‚ùå Rollback error:', error.message);
       throw error;
     } finally {
       client.release();
       await pool.end();
     }
   }

   runRollback().catch(error => {
     console.error('Rollback failed:', error.message);
     process.exit(1);
   });
   ```

## Commit Rules
For **schema changes**:
- Create migration/rollback scripts in `supabase/migrations/`.
- Reference the migration in the commit message (e.g., ‚ÄúAdd migration 20250606_001_create_websites.sql‚Äù).
- Include:
- `supabase/migrations/*.sql`
- `scripts/run-migration.js`, `scripts/rollback-migration.js`
- Related code (e.g., `pages/api/`, `components/`)
- Example:
```bash
git add supabase/migrations/ scripts/ pages/api/
git commit -m "Add migration 20250606_001_create_websites.sql for websites table"
git push origin feature-websites

Create a PR to merge into main. Test in staging first.


For non-schema changes:
Use clear messages (e.g., ‚ÄúAdd client dashboard component‚Äù).


Commit small, focused changes.


General Coding Instructions
Code like a pro‚Äîdon‚Äôt half-ass it:
No Bias: Don‚Äôt say ‚Äúimpossible‚Äù or push complex APIs when simple SQL/Prisma works. If unsure, ask: ‚ÄúIs this the right approach for X?‚Äù


Clean Code:


Use camelCase for JS/TS, snake_case for SQL.


Comment critical logic (e.g., RLS setup).


Modularize code (e.g., reusable functions in pages/api/).


Testing:


Test migrations in atlaswebsites-staging.


Write Jest tests for APIs (e.g., pages/api/websites.ts).


Test React components (e.g., components/ClientDashboard.jsx) with React Testing Library.


Verify schema: SELECT * FROM websites LIMIT 1;


Security:


Enable RLS on all tables:

 ALTER TABLE websites ENABLE ROW LEVEL SECURITY;
CREATE POLICY user_access ON websites
    FOR ALL TO authenticated
    USING (client_id IN (SELECT id FROM clients WHERE user_id = auth.uid()));


Sanitize API inputs to prevent SQL injection.


Version Control:


Use feature branches (e.g., feature-websites).


Keep main stable‚Äîonly merge tested PRs.


Ask Questions: If confused (e.g., ‚ÄúWhat‚Äôs the clients table schema?‚Äù), prompt: ‚ÄúNeed clarification on X. Specify Y?‚Äù


Unprofessional Practices to Avoid
Skipping Migrations: Every schema change needs a migration/rollback script. No excuses.


Sloppy Commits: Don‚Äôt use ‚Äúfixed stuff‚Äù for 500-line changes. Be specific.


Ignoring Errors: Fix Supabase errors (e.g., ‚Äúpgbouncer error‚Äù)‚Äîdon‚Äôt shrug them off.


Hardcoding Secrets: Use env.local for DATABASE_URL/DIRECT_URL.


Untested Changes: Test in staging, not production.


Common Claude Errors & Fixes
‚ÄúSupabase client can‚Äôt do DDL‚Äù: Use Prisma (npx prisma migrate) or pg client.


Removes ?pgbouncer=true: Verify DATABASE_URL in .env.local.


Wrong Password: Use DATABASE_URL/DIRECT_URL from .env.local.


Complex APIs: Use Prisma or direct SQL.


‚ÄúImpossible‚Äù: Follow run-migration.js or Prisma.


Common Supabase Errors
‚ÄúSASL: SCRAM-SERVER-FINAL-MESSAGE‚Äù: Wrong password in .env.local.


‚ÄúConnection refused‚Äù: Missing require('dotenv').config({ path: 'env.local' });.


‚Äúpgbouncer error‚Äù: Use DIRECT_URL for migrations, DATABASE_URL for queries.


Key Files
.env.local: DATABASE_URL, DIRECT_URL (never commit).


schema.prisma: Prisma schema for migrations/queries.


supabase/migrations/: Migration/rollback scripts.


supabase/Claude_Instructions.md: This file.


scripts/run-migration.js: Migration template.


scripts/rollback-migration.js: Rollback template.


scripts/add-indexes-working.js: Proven index script.


scripts/add-database-indexes.ts: Original index script.


pages/api/create-tables.ts: API for table creation.


Summary
Claude, don‚Äôt fuck this up. Use Prisma for migrations (DIRECT_URL) and queries (DATABASE_URL) from .env.local. Keep ?pgbouncer=true for DATABASE_URL. Create migration/rollback scripts for schema changes, reference them in commits, and test in staging. Code cleanly, test everything, and ask me if you‚Äôre lost.